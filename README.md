# Фрейморки ИИ

В репозитории собраны ЛР1-ЛР5 по курсу фреймоврки ИИ
Задания выполнены в `*.ipynb` файлах с комментариями и пояснениями. \
В данном файле описаны основные реализации и выводы по полученным результатам.

Используемые датасеты:

- Классификация. Phishing Websites (OpenML, data_id=4534)  
  Цель: по набору признаков определить, является сайт фишинговым или нет  
- Регрессия. Combined Cycle Power Plant (CCPP, Kaggle)  
  Цель: по температуре, давлению, влажности и вакууму предсказать почасовую выработку электростанции `PE`  

## Структура репозитория

- [Lab1](lr1/Lab1_KNN_Phishing_CCPP.ipynb)  
  k ближайших соседей для классификации и регрессии

- [Lab2](lr2/Lab2_LogReg_LinReg.ipynb)  
  Логистическая регрессия для Phishing и линейная регрессия для CCPP

- [Lab3](lr3/Lab3_DecisionTree.ipynb)  
  Решающее дерево для классификации и регрессии

- [Lab4](lr4/Lab4_RandomForest_v2.ipynb)  
  Случайный лес

- [Lab5](lr5/Lab5_GradientBoosting.ipynb)  
  Градиентный бустинг на деревьях для обеих задач

## Метрики по классификации (Phishing Websites)

В таблице приведены **улучшенные** версии моделей для каждой лр (с подбором наилучших параметров)  

| Algorithm          | Accuracy | MacroF1 | ROC-AUC |
|--------------------|---------:|--------:|--------:|
| KNN                | 0.9724   | 0.9720  | 0.9973* |
| LogisticRegression | 0.9317   | 0.9305  | 0.9806  |
| DecisionTree       | 0.9720   | 0.9716  | 0.9826  |
| RandomForest       | 0.9742   | 0.9738  | 0.9975  |
| GradientBoosting   | 0.9760   | 0.9756  | 0.9968  |

Краткие выводы по метрикам фишинга:

- Лучшее качество по Accuracy и MacroF1 показывает `градиентный бустинг`(т.к. он лучше справляется с задачнй улучщения отдельной метрики), но его отрыв от случайного леса и kNN минимален 
- RandomForest и kNN дают очень близкие результаты, разница в тысячные доли 
- Обычное решающее дерево после подбора глубины практически догоняет kNN  
- Логистическая регрессия значительно хуже по Accuracy и MacroF1, но по ROC-AUC держится около 0.98  

## Метрики по регрессии (CCPP заводы)

Также взяты улучшенные версии моделей  

| Algorithm          |  RMSE  |  MAE  |   R2   |
|--------------------|------:|------:|------:|
| kNN                | 3.5023 | 2.5162 | 0.9577 |
| LinearRegression   | 4.2314 | 3.3517 | 0.9383 |
| DecisionTree       | 3.9463 | 2.9083 | 0.9463 |
| RandomForest       | 3.0990 | 2.2138 | 0.9669 |
| GradientBoosting   | 2.9163 | 2.0859 | 0.9707 |

Краткие выводы для CCPP по метриквм:

- Линейная регрессия показывает наибольшие ошибки, зависимость выработки от признаков явно нелинейная  
- Переход к одиночному дереву снижает RMSE и MAE, но по R^2 дерево все еще проигрывает ансамблям  
- kNN лучше линейной регрессии и дерева, но проигрывает ансамблям на деревьях  
- Наилучшие метрики дает градиентный бустинг, у которого видим минимальные RMSE и MAE, и максимальное R^2 
- RandomForest немного уступает бустингу, но остается очень сильной и более стабильной моделью, которая проще тюнится  

## Итоговый вывод

Реализованные ЛР показали, что для задачи классификации фишинговых сайтов простые модели, такие как kNN и логистическая регрессия, формируют неплохой начальный уровень качества, однако уже на этих данных заметно преимущество деревьев и ансамблевых методов. \
В задаче регрессии(предикт потребления мощностей электростанции) линейная регрессия существенно уступает KNN и моделям на деревьях потому что зависимость целевой переменной от входных признаков оказалась явно нелинейной, а наилучшие значения RMSE, MAE и R^2 были получены именно градиентным бустингом. \
Решающее дерево в обеих постановках проявило себя как неплохой базовый нелинейный метод, но при отсутствии ограничений по глубине и размеру листьев склонно к переобучению, что требует обязательного подбора регуляризационных параметров. \
Случайный лес продемонстрировал себя как более стабильная модель. Он практически всегда обеспечивает высокий уровень качества без экстремально тонкого тюнинга. Из плюсов - устойчив к шуму за счёт бэггинга и случайного подбора признаков. \
`Наилучшие метрики как в классификации, так и в регрессии в целом показал градиентный бустинг`, однако его применение потребовало более аккуратной настройки числа деревьев, глубины базовых моделей, скорости обучения и доли подвыборки, 
а также сопровождалось заметным ростом времени обучения по сравнению с KNN и одиночными деревьями(поэтому при подборе оптимальных параметров я использовал рандомизированный K-Folding т.к. все обучение шло на CPU). \
Самописные реализации KNN, логистической регрессии, деревьев, случайного леса и бустинга оказались полезны для понимания внутренней логики алгоритмов, но ожидаемо уступили по качеству реализациям библиотеки scikit-learn, что дополнительно подтверждает целесообразность использования готовых фреймворков. \
В целом по результатам всех пяти лабораторных работ видно, что по мере усложнения моделей качество на одних и тех же данных возрастает, одновременно повышаются требования к тюнингу гиперпараметров и вычислительным ресурсам, а выбор конкретного алгоритма должен учитывать компромисс между точностью, устойчивостью и сложностью применения.
